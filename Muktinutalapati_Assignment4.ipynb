{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vamsikrishna1804/INFO-5505-Advanced-Machine-Learning-for-Data-Scientists-/blob/main/Muktinutalapati_Assignment4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUKCShy9E819"
      },
      "source": [
        "**Dataset**: [Breast Cancer Wisconsin Dataset](https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data?resource=download)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVakuOE8CvD3"
      },
      "outputs": [],
      "source": [
        "#importing necessary libraries\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9Eoo9hPFsDP"
      },
      "source": [
        "**Loading the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "EsftL5kCFqW1",
        "outputId": "ffe65a1e-37c6-48d1-b551-19239007f6f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
              "0      842302         M        17.99         10.38          122.80     1001.0   \n",
              "1      842517         M        20.57         17.77          132.90     1326.0   \n",
              "2    84300903         M        19.69         21.25          130.00     1203.0   \n",
              "3    84348301         M        11.42         20.38           77.58      386.1   \n",
              "4    84358402         M        20.29         14.34          135.10     1297.0   \n",
              "..        ...       ...          ...           ...             ...        ...   \n",
              "564    926424         M        21.56         22.39          142.00     1479.0   \n",
              "565    926682         M        20.13         28.25          131.20     1261.0   \n",
              "566    926954         M        16.60         28.08          108.30      858.1   \n",
              "567    927241         M        20.60         29.33          140.10     1265.0   \n",
              "568     92751         B         7.76         24.54           47.92      181.0   \n",
              "\n",
              "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
              "0            0.11840           0.27760         0.30010              0.14710   \n",
              "1            0.08474           0.07864         0.08690              0.07017   \n",
              "2            0.10960           0.15990         0.19740              0.12790   \n",
              "3            0.14250           0.28390         0.24140              0.10520   \n",
              "4            0.10030           0.13280         0.19800              0.10430   \n",
              "..               ...               ...             ...                  ...   \n",
              "564          0.11100           0.11590         0.24390              0.13890   \n",
              "565          0.09780           0.10340         0.14400              0.09791   \n",
              "566          0.08455           0.10230         0.09251              0.05302   \n",
              "567          0.11780           0.27700         0.35140              0.15200   \n",
              "568          0.05263           0.04362         0.00000              0.00000   \n",
              "\n",
              "     ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
              "0    ...          17.33           184.60      2019.0           0.16220   \n",
              "1    ...          23.41           158.80      1956.0           0.12380   \n",
              "2    ...          25.53           152.50      1709.0           0.14440   \n",
              "3    ...          26.50            98.87       567.7           0.20980   \n",
              "4    ...          16.67           152.20      1575.0           0.13740   \n",
              "..   ...            ...              ...         ...               ...   \n",
              "564  ...          26.40           166.10      2027.0           0.14100   \n",
              "565  ...          38.25           155.00      1731.0           0.11660   \n",
              "566  ...          34.12           126.70      1124.0           0.11390   \n",
              "567  ...          39.42           184.60      1821.0           0.16500   \n",
              "568  ...          30.37            59.16       268.6           0.08996   \n",
              "\n",
              "     compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
              "0              0.66560           0.7119                0.2654          0.4601   \n",
              "1              0.18660           0.2416                0.1860          0.2750   \n",
              "2              0.42450           0.4504                0.2430          0.3613   \n",
              "3              0.86630           0.6869                0.2575          0.6638   \n",
              "4              0.20500           0.4000                0.1625          0.2364   \n",
              "..                 ...              ...                   ...             ...   \n",
              "564            0.21130           0.4107                0.2216          0.2060   \n",
              "565            0.19220           0.3215                0.1628          0.2572   \n",
              "566            0.30940           0.3403                0.1418          0.2218   \n",
              "567            0.86810           0.9387                0.2650          0.4087   \n",
              "568            0.06444           0.0000                0.0000          0.2871   \n",
              "\n",
              "     fractal_dimension_worst  Unnamed: 32  \n",
              "0                    0.11890          NaN  \n",
              "1                    0.08902          NaN  \n",
              "2                    0.08758          NaN  \n",
              "3                    0.17300          NaN  \n",
              "4                    0.07678          NaN  \n",
              "..                       ...          ...  \n",
              "564                  0.07115          NaN  \n",
              "565                  0.06637          NaN  \n",
              "566                  0.07820          NaN  \n",
              "567                  0.12400          NaN  \n",
              "568                  0.07039          NaN  \n",
              "\n",
              "[569 rows x 33 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-441ea7f0-5308-4dff-9bf7-6949c19b9d5b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>...</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>...</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>...</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>...</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>...</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>926424</td>\n",
              "      <td>M</td>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>...</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>926682</td>\n",
              "      <td>M</td>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>...</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>926954</td>\n",
              "      <td>M</td>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>...</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>927241</td>\n",
              "      <td>M</td>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>...</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>92751</td>\n",
              "      <td>B</td>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 33 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-441ea7f0-5308-4dff-9bf7-6949c19b9d5b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-441ea7f0-5308-4dff-9bf7-6949c19b9d5b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-441ea7f0-5308-4dff-9bf7-6949c19b9d5b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "df=pd.read_csv('data.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjvLMuF5GJlL"
      },
      "source": [
        "From the above dataframe, it is evident that 33 column is empty which is of no use and also id field which is numerical discrete is also of no use as it doesn't add any value for our model. For model effectiveness, these two fields are removed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98jWQzX-g6su"
      },
      "source": [
        "**Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uvg0_hmkGe0o",
        "outputId": "f4fe7b34-9c81-423b-98c2-103b64cdb9c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the number of columns:  31\n"
          ]
        }
      ],
      "source": [
        "del df['id']\n",
        "del df['Unnamed: 32']\n",
        "\n",
        "print('the number of columns: ', len(df.columns))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nW6eX6-YeH9Y"
      },
      "source": [
        "**Descriptive Statistics of Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "9UZt1g7SeKGZ",
        "outputId": "db77dc25-0ae0-41c1-83bc-ef80c2f58b3f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       radius_mean  texture_mean  perimeter_mean    area_mean  \\\n",
              "count   569.000000    569.000000      569.000000   569.000000   \n",
              "mean     14.127292     19.289649       91.969033   654.889104   \n",
              "std       3.524049      4.301036       24.298981   351.914129   \n",
              "min       6.981000      9.710000       43.790000   143.500000   \n",
              "25%      11.700000     16.170000       75.170000   420.300000   \n",
              "50%      13.370000     18.840000       86.240000   551.100000   \n",
              "75%      15.780000     21.800000      104.100000   782.700000   \n",
              "max      28.110000     39.280000      188.500000  2501.000000   \n",
              "\n",
              "       smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
              "count       569.000000        569.000000      569.000000           569.000000   \n",
              "mean          0.096360          0.104341        0.088799             0.048919   \n",
              "std           0.014064          0.052813        0.079720             0.038803   \n",
              "min           0.052630          0.019380        0.000000             0.000000   \n",
              "25%           0.086370          0.064920        0.029560             0.020310   \n",
              "50%           0.095870          0.092630        0.061540             0.033500   \n",
              "75%           0.105300          0.130400        0.130700             0.074000   \n",
              "max           0.163400          0.345400        0.426800             0.201200   \n",
              "\n",
              "       symmetry_mean  fractal_dimension_mean  ...  radius_worst  \\\n",
              "count     569.000000              569.000000  ...    569.000000   \n",
              "mean        0.181162                0.062798  ...     16.269190   \n",
              "std         0.027414                0.007060  ...      4.833242   \n",
              "min         0.106000                0.049960  ...      7.930000   \n",
              "25%         0.161900                0.057700  ...     13.010000   \n",
              "50%         0.179200                0.061540  ...     14.970000   \n",
              "75%         0.195700                0.066120  ...     18.790000   \n",
              "max         0.304000                0.097440  ...     36.040000   \n",
              "\n",
              "       texture_worst  perimeter_worst   area_worst  smoothness_worst  \\\n",
              "count     569.000000       569.000000   569.000000        569.000000   \n",
              "mean       25.677223       107.261213   880.583128          0.132369   \n",
              "std         6.146258        33.602542   569.356993          0.022832   \n",
              "min        12.020000        50.410000   185.200000          0.071170   \n",
              "25%        21.080000        84.110000   515.300000          0.116600   \n",
              "50%        25.410000        97.660000   686.500000          0.131300   \n",
              "75%        29.720000       125.400000  1084.000000          0.146000   \n",
              "max        49.540000       251.200000  4254.000000          0.222600   \n",
              "\n",
              "       compactness_worst  concavity_worst  concave points_worst  \\\n",
              "count         569.000000       569.000000            569.000000   \n",
              "mean            0.254265         0.272188              0.114606   \n",
              "std             0.157336         0.208624              0.065732   \n",
              "min             0.027290         0.000000              0.000000   \n",
              "25%             0.147200         0.114500              0.064930   \n",
              "50%             0.211900         0.226700              0.099930   \n",
              "75%             0.339100         0.382900              0.161400   \n",
              "max             1.058000         1.252000              0.291000   \n",
              "\n",
              "       symmetry_worst  fractal_dimension_worst  \n",
              "count      569.000000               569.000000  \n",
              "mean         0.290076                 0.083946  \n",
              "std          0.061867                 0.018061  \n",
              "min          0.156500                 0.055040  \n",
              "25%          0.250400                 0.071460  \n",
              "50%          0.282200                 0.080040  \n",
              "75%          0.317900                 0.092080  \n",
              "max          0.663800                 0.207500  \n",
              "\n",
              "[8 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-47f4be79-8169-4897-b13f-4c15c7effb56\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>14.127292</td>\n",
              "      <td>19.289649</td>\n",
              "      <td>91.969033</td>\n",
              "      <td>654.889104</td>\n",
              "      <td>0.096360</td>\n",
              "      <td>0.104341</td>\n",
              "      <td>0.088799</td>\n",
              "      <td>0.048919</td>\n",
              "      <td>0.181162</td>\n",
              "      <td>0.062798</td>\n",
              "      <td>...</td>\n",
              "      <td>16.269190</td>\n",
              "      <td>25.677223</td>\n",
              "      <td>107.261213</td>\n",
              "      <td>880.583128</td>\n",
              "      <td>0.132369</td>\n",
              "      <td>0.254265</td>\n",
              "      <td>0.272188</td>\n",
              "      <td>0.114606</td>\n",
              "      <td>0.290076</td>\n",
              "      <td>0.083946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.524049</td>\n",
              "      <td>4.301036</td>\n",
              "      <td>24.298981</td>\n",
              "      <td>351.914129</td>\n",
              "      <td>0.014064</td>\n",
              "      <td>0.052813</td>\n",
              "      <td>0.079720</td>\n",
              "      <td>0.038803</td>\n",
              "      <td>0.027414</td>\n",
              "      <td>0.007060</td>\n",
              "      <td>...</td>\n",
              "      <td>4.833242</td>\n",
              "      <td>6.146258</td>\n",
              "      <td>33.602542</td>\n",
              "      <td>569.356993</td>\n",
              "      <td>0.022832</td>\n",
              "      <td>0.157336</td>\n",
              "      <td>0.208624</td>\n",
              "      <td>0.065732</td>\n",
              "      <td>0.061867</td>\n",
              "      <td>0.018061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>6.981000</td>\n",
              "      <td>9.710000</td>\n",
              "      <td>43.790000</td>\n",
              "      <td>143.500000</td>\n",
              "      <td>0.052630</td>\n",
              "      <td>0.019380</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.106000</td>\n",
              "      <td>0.049960</td>\n",
              "      <td>...</td>\n",
              "      <td>7.930000</td>\n",
              "      <td>12.020000</td>\n",
              "      <td>50.410000</td>\n",
              "      <td>185.200000</td>\n",
              "      <td>0.071170</td>\n",
              "      <td>0.027290</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.156500</td>\n",
              "      <td>0.055040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>11.700000</td>\n",
              "      <td>16.170000</td>\n",
              "      <td>75.170000</td>\n",
              "      <td>420.300000</td>\n",
              "      <td>0.086370</td>\n",
              "      <td>0.064920</td>\n",
              "      <td>0.029560</td>\n",
              "      <td>0.020310</td>\n",
              "      <td>0.161900</td>\n",
              "      <td>0.057700</td>\n",
              "      <td>...</td>\n",
              "      <td>13.010000</td>\n",
              "      <td>21.080000</td>\n",
              "      <td>84.110000</td>\n",
              "      <td>515.300000</td>\n",
              "      <td>0.116600</td>\n",
              "      <td>0.147200</td>\n",
              "      <td>0.114500</td>\n",
              "      <td>0.064930</td>\n",
              "      <td>0.250400</td>\n",
              "      <td>0.071460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>13.370000</td>\n",
              "      <td>18.840000</td>\n",
              "      <td>86.240000</td>\n",
              "      <td>551.100000</td>\n",
              "      <td>0.095870</td>\n",
              "      <td>0.092630</td>\n",
              "      <td>0.061540</td>\n",
              "      <td>0.033500</td>\n",
              "      <td>0.179200</td>\n",
              "      <td>0.061540</td>\n",
              "      <td>...</td>\n",
              "      <td>14.970000</td>\n",
              "      <td>25.410000</td>\n",
              "      <td>97.660000</td>\n",
              "      <td>686.500000</td>\n",
              "      <td>0.131300</td>\n",
              "      <td>0.211900</td>\n",
              "      <td>0.226700</td>\n",
              "      <td>0.099930</td>\n",
              "      <td>0.282200</td>\n",
              "      <td>0.080040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>15.780000</td>\n",
              "      <td>21.800000</td>\n",
              "      <td>104.100000</td>\n",
              "      <td>782.700000</td>\n",
              "      <td>0.105300</td>\n",
              "      <td>0.130400</td>\n",
              "      <td>0.130700</td>\n",
              "      <td>0.074000</td>\n",
              "      <td>0.195700</td>\n",
              "      <td>0.066120</td>\n",
              "      <td>...</td>\n",
              "      <td>18.790000</td>\n",
              "      <td>29.720000</td>\n",
              "      <td>125.400000</td>\n",
              "      <td>1084.000000</td>\n",
              "      <td>0.146000</td>\n",
              "      <td>0.339100</td>\n",
              "      <td>0.382900</td>\n",
              "      <td>0.161400</td>\n",
              "      <td>0.317900</td>\n",
              "      <td>0.092080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>28.110000</td>\n",
              "      <td>39.280000</td>\n",
              "      <td>188.500000</td>\n",
              "      <td>2501.000000</td>\n",
              "      <td>0.163400</td>\n",
              "      <td>0.345400</td>\n",
              "      <td>0.426800</td>\n",
              "      <td>0.201200</td>\n",
              "      <td>0.304000</td>\n",
              "      <td>0.097440</td>\n",
              "      <td>...</td>\n",
              "      <td>36.040000</td>\n",
              "      <td>49.540000</td>\n",
              "      <td>251.200000</td>\n",
              "      <td>4254.000000</td>\n",
              "      <td>0.222600</td>\n",
              "      <td>1.058000</td>\n",
              "      <td>1.252000</td>\n",
              "      <td>0.291000</td>\n",
              "      <td>0.663800</td>\n",
              "      <td>0.207500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-47f4be79-8169-4897-b13f-4c15c7effb56')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-47f4be79-8169-4897-b13f-4c15c7effb56 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-47f4be79-8169-4897-b13f-4c15c7effb56');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n19eB3ibebz0"
      },
      "source": [
        "From the above statistics, it is evident that values of min, max,standard deviation and mean have values in different scales. In this random forest model is capable of handling different scale data as it will make local optimums. Hence Standardization or Normalization techniques are not required to apply for this model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_GPpwd1fdca"
      },
      "source": [
        "**Explore missing values**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoRe5c4afbOJ",
        "outputId": "09546df1-f26b-49ca-8ba4-3bd5f54be0e7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "diagnosis                  0\n",
              "radius_mean                0\n",
              "texture_mean               0\n",
              "perimeter_mean             0\n",
              "area_mean                  0\n",
              "smoothness_mean            0\n",
              "compactness_mean           0\n",
              "concavity_mean             0\n",
              "concave points_mean        0\n",
              "symmetry_mean              0\n",
              "fractal_dimension_mean     0\n",
              "radius_se                  0\n",
              "texture_se                 0\n",
              "perimeter_se               0\n",
              "area_se                    0\n",
              "smoothness_se              0\n",
              "compactness_se             0\n",
              "concavity_se               0\n",
              "concave points_se          0\n",
              "symmetry_se                0\n",
              "fractal_dimension_se       0\n",
              "radius_worst               0\n",
              "texture_worst              0\n",
              "perimeter_worst            0\n",
              "area_worst                 0\n",
              "smoothness_worst           0\n",
              "compactness_worst          0\n",
              "concavity_worst            0\n",
              "concave points_worst       0\n",
              "symmetry_worst             0\n",
              "fractal_dimension_worst    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-THehSJefmwO"
      },
      "source": [
        "As data does not have any missing values, we can use this cleaned dataset for modeling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wnDaU6efymj"
      },
      "source": [
        "In this dataset, dependent variable is diagonsis which is mentioned as Malignant (M) or Benign (B). In order to classify this by random forest model, we will be assigning 1 to Malignant and 0 if the diagnosis is Benign. \n",
        "\n",
        "Dependent variable distribution is plotted below to find out how data distribution is done in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwnfuzR-gN20",
        "outputId": "c9e4010f-9cfa-4b84-8410-ca21c72ca8f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class distribution in the dependent variable: \n",
            " B    357\n",
            "M    212\n",
            "Name: diagnosis, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print( 'class distribution in the dependent variable: \\n',df['diagnosis'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "xrJGFuBRgUtV",
        "outputId": "f522b9b5-23d7-467e-f1a5-f2e6f32e53da"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "sns.countplot(x='diagnosis', data=df)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fxh7o8mAgZ6O"
      },
      "source": [
        "From the above count plot, it is seen that there are benign type more in the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjufJewvhLz0"
      },
      "source": [
        "For the model classification, converting the descriptive values into binary for the dependent variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 944
        },
        "id": "jK93foB5hUi2",
        "outputId": "5e6fa384-d874-4037-f1af-ab41230b0e6c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
              "0           1       17.990         10.38          122.80     1001.0   \n",
              "1           1       20.570         17.77          132.90     1326.0   \n",
              "2           1       19.690         21.25          130.00     1203.0   \n",
              "3           1       11.420         20.38           77.58      386.1   \n",
              "4           1       20.290         14.34          135.10     1297.0   \n",
              "5           1       12.450         15.70           82.57      477.1   \n",
              "6           1       18.250         19.98          119.60     1040.0   \n",
              "7           1       13.710         20.83           90.20      577.9   \n",
              "8           1       13.000         21.82           87.50      519.8   \n",
              "9           1       12.460         24.04           83.97      475.9   \n",
              "10          1       16.020         23.24          102.70      797.8   \n",
              "11          1       15.780         17.89          103.60      781.0   \n",
              "12          1       19.170         24.80          132.40     1123.0   \n",
              "13          1       15.850         23.95          103.70      782.7   \n",
              "14          1       13.730         22.61           93.60      578.3   \n",
              "15          1       14.540         27.54           96.73      658.8   \n",
              "16          1       14.680         20.13           94.74      684.5   \n",
              "17          1       16.130         20.68          108.10      798.8   \n",
              "18          1       19.810         22.15          130.00     1260.0   \n",
              "19          0       13.540         14.36           87.46      566.3   \n",
              "20          0       13.080         15.71           85.63      520.0   \n",
              "21          0        9.504         12.44           60.34      273.9   \n",
              "22          1       15.340         14.26          102.50      704.4   \n",
              "23          1       21.160         23.04          137.20     1404.0   \n",
              "24          1       16.650         21.38          110.00      904.6   \n",
              "\n",
              "    smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
              "0           0.11840           0.27760         0.30010              0.14710   \n",
              "1           0.08474           0.07864         0.08690              0.07017   \n",
              "2           0.10960           0.15990         0.19740              0.12790   \n",
              "3           0.14250           0.28390         0.24140              0.10520   \n",
              "4           0.10030           0.13280         0.19800              0.10430   \n",
              "5           0.12780           0.17000         0.15780              0.08089   \n",
              "6           0.09463           0.10900         0.11270              0.07400   \n",
              "7           0.11890           0.16450         0.09366              0.05985   \n",
              "8           0.12730           0.19320         0.18590              0.09353   \n",
              "9           0.11860           0.23960         0.22730              0.08543   \n",
              "10          0.08206           0.06669         0.03299              0.03323   \n",
              "11          0.09710           0.12920         0.09954              0.06606   \n",
              "12          0.09740           0.24580         0.20650              0.11180   \n",
              "13          0.08401           0.10020         0.09938              0.05364   \n",
              "14          0.11310           0.22930         0.21280              0.08025   \n",
              "15          0.11390           0.15950         0.16390              0.07364   \n",
              "16          0.09867           0.07200         0.07395              0.05259   \n",
              "17          0.11700           0.20220         0.17220              0.10280   \n",
              "18          0.09831           0.10270         0.14790              0.09498   \n",
              "19          0.09779           0.08129         0.06664              0.04781   \n",
              "20          0.10750           0.12700         0.04568              0.03110   \n",
              "21          0.10240           0.06492         0.02956              0.02076   \n",
              "22          0.10730           0.21350         0.20770              0.09756   \n",
              "23          0.09428           0.10220         0.10970              0.08632   \n",
              "24          0.11210           0.14570         0.15250              0.09170   \n",
              "\n",
              "    symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
              "0          0.2419  ...         25.38          17.33           184.60   \n",
              "1          0.1812  ...         24.99          23.41           158.80   \n",
              "2          0.2069  ...         23.57          25.53           152.50   \n",
              "3          0.2597  ...         14.91          26.50            98.87   \n",
              "4          0.1809  ...         22.54          16.67           152.20   \n",
              "5          0.2087  ...         15.47          23.75           103.40   \n",
              "6          0.1794  ...         22.88          27.66           153.20   \n",
              "7          0.2196  ...         17.06          28.14           110.60   \n",
              "8          0.2350  ...         15.49          30.73           106.20   \n",
              "9          0.2030  ...         15.09          40.68            97.65   \n",
              "10         0.1528  ...         19.19          33.88           123.80   \n",
              "11         0.1842  ...         20.42          27.28           136.50   \n",
              "12         0.2397  ...         20.96          29.94           151.70   \n",
              "13         0.1847  ...         16.84          27.66           112.00   \n",
              "14         0.2069  ...         15.03          32.01           108.80   \n",
              "15         0.2303  ...         17.46          37.13           124.10   \n",
              "16         0.1586  ...         19.07          30.88           123.40   \n",
              "17         0.2164  ...         20.96          31.48           136.80   \n",
              "18         0.1582  ...         27.32          30.88           186.80   \n",
              "19         0.1885  ...         15.11          19.26            99.70   \n",
              "20         0.1967  ...         14.50          20.49            96.09   \n",
              "21         0.1815  ...         10.23          15.66            65.13   \n",
              "22         0.2521  ...         18.07          19.08           125.10   \n",
              "23         0.1769  ...         29.17          35.59           188.00   \n",
              "24         0.1995  ...         26.46          31.56           177.00   \n",
              "\n",
              "    area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
              "0       2019.0            0.1622             0.6656          0.71190   \n",
              "1       1956.0            0.1238             0.1866          0.24160   \n",
              "2       1709.0            0.1444             0.4245          0.45040   \n",
              "3        567.7            0.2098             0.8663          0.68690   \n",
              "4       1575.0            0.1374             0.2050          0.40000   \n",
              "5        741.6            0.1791             0.5249          0.53550   \n",
              "6       1606.0            0.1442             0.2576          0.37840   \n",
              "7        897.0            0.1654             0.3682          0.26780   \n",
              "8        739.3            0.1703             0.5401          0.53900   \n",
              "9        711.4            0.1853             1.0580          1.10500   \n",
              "10      1150.0            0.1181             0.1551          0.14590   \n",
              "11      1299.0            0.1396             0.5609          0.39650   \n",
              "12      1332.0            0.1037             0.3903          0.36390   \n",
              "13       876.5            0.1131             0.1924          0.23220   \n",
              "14       697.7            0.1651             0.7725          0.69430   \n",
              "15       943.2            0.1678             0.6577          0.70260   \n",
              "16      1138.0            0.1464             0.1871          0.29140   \n",
              "17      1315.0            0.1789             0.4233          0.47840   \n",
              "18      2398.0            0.1512             0.3150          0.53720   \n",
              "19       711.2            0.1440             0.1773          0.23900   \n",
              "20       630.5            0.1312             0.2776          0.18900   \n",
              "21       314.9            0.1324             0.1148          0.08867   \n",
              "22       980.9            0.1390             0.5954          0.63050   \n",
              "23      2615.0            0.1401             0.2600          0.31550   \n",
              "24      2215.0            0.1805             0.3578          0.46950   \n",
              "\n",
              "    concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
              "0                0.26540          0.4601                  0.11890  \n",
              "1                0.18600          0.2750                  0.08902  \n",
              "2                0.24300          0.3613                  0.08758  \n",
              "3                0.25750          0.6638                  0.17300  \n",
              "4                0.16250          0.2364                  0.07678  \n",
              "5                0.17410          0.3985                  0.12440  \n",
              "6                0.19320          0.3063                  0.08368  \n",
              "7                0.15560          0.3196                  0.11510  \n",
              "8                0.20600          0.4378                  0.10720  \n",
              "9                0.22100          0.4366                  0.20750  \n",
              "10               0.09975          0.2948                  0.08452  \n",
              "11               0.18100          0.3792                  0.10480  \n",
              "12               0.17670          0.3176                  0.10230  \n",
              "13               0.11190          0.2809                  0.06287  \n",
              "14               0.22080          0.3596                  0.14310  \n",
              "15               0.17120          0.4218                  0.13410  \n",
              "16               0.16090          0.3029                  0.08216  \n",
              "17               0.20730          0.3706                  0.11420  \n",
              "18               0.23880          0.2768                  0.07615  \n",
              "19               0.12880          0.2977                  0.07259  \n",
              "20               0.07283          0.3184                  0.08183  \n",
              "21               0.06227          0.2450                  0.07773  \n",
              "22               0.23930          0.4667                  0.09946  \n",
              "23               0.20090          0.2822                  0.07526  \n",
              "24               0.20950          0.3613                  0.09564  \n",
              "\n",
              "[25 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bb159c4b-60a3-4a28-9ff2-0f70c4012b17\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>17.990</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>...</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.71190</td>\n",
              "      <td>0.26540</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>20.570</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>...</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.24160</td>\n",
              "      <td>0.18600</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>19.690</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>...</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.45040</td>\n",
              "      <td>0.24300</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>11.420</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>...</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.68690</td>\n",
              "      <td>0.25750</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>20.290</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>...</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.40000</td>\n",
              "      <td>0.16250</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>12.450</td>\n",
              "      <td>15.70</td>\n",
              "      <td>82.57</td>\n",
              "      <td>477.1</td>\n",
              "      <td>0.12780</td>\n",
              "      <td>0.17000</td>\n",
              "      <td>0.15780</td>\n",
              "      <td>0.08089</td>\n",
              "      <td>0.2087</td>\n",
              "      <td>...</td>\n",
              "      <td>15.47</td>\n",
              "      <td>23.75</td>\n",
              "      <td>103.40</td>\n",
              "      <td>741.6</td>\n",
              "      <td>0.1791</td>\n",
              "      <td>0.5249</td>\n",
              "      <td>0.53550</td>\n",
              "      <td>0.17410</td>\n",
              "      <td>0.3985</td>\n",
              "      <td>0.12440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>18.250</td>\n",
              "      <td>19.98</td>\n",
              "      <td>119.60</td>\n",
              "      <td>1040.0</td>\n",
              "      <td>0.09463</td>\n",
              "      <td>0.10900</td>\n",
              "      <td>0.11270</td>\n",
              "      <td>0.07400</td>\n",
              "      <td>0.1794</td>\n",
              "      <td>...</td>\n",
              "      <td>22.88</td>\n",
              "      <td>27.66</td>\n",
              "      <td>153.20</td>\n",
              "      <td>1606.0</td>\n",
              "      <td>0.1442</td>\n",
              "      <td>0.2576</td>\n",
              "      <td>0.37840</td>\n",
              "      <td>0.19320</td>\n",
              "      <td>0.3063</td>\n",
              "      <td>0.08368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>13.710</td>\n",
              "      <td>20.83</td>\n",
              "      <td>90.20</td>\n",
              "      <td>577.9</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>0.16450</td>\n",
              "      <td>0.09366</td>\n",
              "      <td>0.05985</td>\n",
              "      <td>0.2196</td>\n",
              "      <td>...</td>\n",
              "      <td>17.06</td>\n",
              "      <td>28.14</td>\n",
              "      <td>110.60</td>\n",
              "      <td>897.0</td>\n",
              "      <td>0.1654</td>\n",
              "      <td>0.3682</td>\n",
              "      <td>0.26780</td>\n",
              "      <td>0.15560</td>\n",
              "      <td>0.3196</td>\n",
              "      <td>0.11510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>13.000</td>\n",
              "      <td>21.82</td>\n",
              "      <td>87.50</td>\n",
              "      <td>519.8</td>\n",
              "      <td>0.12730</td>\n",
              "      <td>0.19320</td>\n",
              "      <td>0.18590</td>\n",
              "      <td>0.09353</td>\n",
              "      <td>0.2350</td>\n",
              "      <td>...</td>\n",
              "      <td>15.49</td>\n",
              "      <td>30.73</td>\n",
              "      <td>106.20</td>\n",
              "      <td>739.3</td>\n",
              "      <td>0.1703</td>\n",
              "      <td>0.5401</td>\n",
              "      <td>0.53900</td>\n",
              "      <td>0.20600</td>\n",
              "      <td>0.4378</td>\n",
              "      <td>0.10720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>12.460</td>\n",
              "      <td>24.04</td>\n",
              "      <td>83.97</td>\n",
              "      <td>475.9</td>\n",
              "      <td>0.11860</td>\n",
              "      <td>0.23960</td>\n",
              "      <td>0.22730</td>\n",
              "      <td>0.08543</td>\n",
              "      <td>0.2030</td>\n",
              "      <td>...</td>\n",
              "      <td>15.09</td>\n",
              "      <td>40.68</td>\n",
              "      <td>97.65</td>\n",
              "      <td>711.4</td>\n",
              "      <td>0.1853</td>\n",
              "      <td>1.0580</td>\n",
              "      <td>1.10500</td>\n",
              "      <td>0.22100</td>\n",
              "      <td>0.4366</td>\n",
              "      <td>0.20750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1</td>\n",
              "      <td>16.020</td>\n",
              "      <td>23.24</td>\n",
              "      <td>102.70</td>\n",
              "      <td>797.8</td>\n",
              "      <td>0.08206</td>\n",
              "      <td>0.06669</td>\n",
              "      <td>0.03299</td>\n",
              "      <td>0.03323</td>\n",
              "      <td>0.1528</td>\n",
              "      <td>...</td>\n",
              "      <td>19.19</td>\n",
              "      <td>33.88</td>\n",
              "      <td>123.80</td>\n",
              "      <td>1150.0</td>\n",
              "      <td>0.1181</td>\n",
              "      <td>0.1551</td>\n",
              "      <td>0.14590</td>\n",
              "      <td>0.09975</td>\n",
              "      <td>0.2948</td>\n",
              "      <td>0.08452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1</td>\n",
              "      <td>15.780</td>\n",
              "      <td>17.89</td>\n",
              "      <td>103.60</td>\n",
              "      <td>781.0</td>\n",
              "      <td>0.09710</td>\n",
              "      <td>0.12920</td>\n",
              "      <td>0.09954</td>\n",
              "      <td>0.06606</td>\n",
              "      <td>0.1842</td>\n",
              "      <td>...</td>\n",
              "      <td>20.42</td>\n",
              "      <td>27.28</td>\n",
              "      <td>136.50</td>\n",
              "      <td>1299.0</td>\n",
              "      <td>0.1396</td>\n",
              "      <td>0.5609</td>\n",
              "      <td>0.39650</td>\n",
              "      <td>0.18100</td>\n",
              "      <td>0.3792</td>\n",
              "      <td>0.10480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1</td>\n",
              "      <td>19.170</td>\n",
              "      <td>24.80</td>\n",
              "      <td>132.40</td>\n",
              "      <td>1123.0</td>\n",
              "      <td>0.09740</td>\n",
              "      <td>0.24580</td>\n",
              "      <td>0.20650</td>\n",
              "      <td>0.11180</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>...</td>\n",
              "      <td>20.96</td>\n",
              "      <td>29.94</td>\n",
              "      <td>151.70</td>\n",
              "      <td>1332.0</td>\n",
              "      <td>0.1037</td>\n",
              "      <td>0.3903</td>\n",
              "      <td>0.36390</td>\n",
              "      <td>0.17670</td>\n",
              "      <td>0.3176</td>\n",
              "      <td>0.10230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1</td>\n",
              "      <td>15.850</td>\n",
              "      <td>23.95</td>\n",
              "      <td>103.70</td>\n",
              "      <td>782.7</td>\n",
              "      <td>0.08401</td>\n",
              "      <td>0.10020</td>\n",
              "      <td>0.09938</td>\n",
              "      <td>0.05364</td>\n",
              "      <td>0.1847</td>\n",
              "      <td>...</td>\n",
              "      <td>16.84</td>\n",
              "      <td>27.66</td>\n",
              "      <td>112.00</td>\n",
              "      <td>876.5</td>\n",
              "      <td>0.1131</td>\n",
              "      <td>0.1924</td>\n",
              "      <td>0.23220</td>\n",
              "      <td>0.11190</td>\n",
              "      <td>0.2809</td>\n",
              "      <td>0.06287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1</td>\n",
              "      <td>13.730</td>\n",
              "      <td>22.61</td>\n",
              "      <td>93.60</td>\n",
              "      <td>578.3</td>\n",
              "      <td>0.11310</td>\n",
              "      <td>0.22930</td>\n",
              "      <td>0.21280</td>\n",
              "      <td>0.08025</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>...</td>\n",
              "      <td>15.03</td>\n",
              "      <td>32.01</td>\n",
              "      <td>108.80</td>\n",
              "      <td>697.7</td>\n",
              "      <td>0.1651</td>\n",
              "      <td>0.7725</td>\n",
              "      <td>0.69430</td>\n",
              "      <td>0.22080</td>\n",
              "      <td>0.3596</td>\n",
              "      <td>0.14310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1</td>\n",
              "      <td>14.540</td>\n",
              "      <td>27.54</td>\n",
              "      <td>96.73</td>\n",
              "      <td>658.8</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.15950</td>\n",
              "      <td>0.16390</td>\n",
              "      <td>0.07364</td>\n",
              "      <td>0.2303</td>\n",
              "      <td>...</td>\n",
              "      <td>17.46</td>\n",
              "      <td>37.13</td>\n",
              "      <td>124.10</td>\n",
              "      <td>943.2</td>\n",
              "      <td>0.1678</td>\n",
              "      <td>0.6577</td>\n",
              "      <td>0.70260</td>\n",
              "      <td>0.17120</td>\n",
              "      <td>0.4218</td>\n",
              "      <td>0.13410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1</td>\n",
              "      <td>14.680</td>\n",
              "      <td>20.13</td>\n",
              "      <td>94.74</td>\n",
              "      <td>684.5</td>\n",
              "      <td>0.09867</td>\n",
              "      <td>0.07200</td>\n",
              "      <td>0.07395</td>\n",
              "      <td>0.05259</td>\n",
              "      <td>0.1586</td>\n",
              "      <td>...</td>\n",
              "      <td>19.07</td>\n",
              "      <td>30.88</td>\n",
              "      <td>123.40</td>\n",
              "      <td>1138.0</td>\n",
              "      <td>0.1464</td>\n",
              "      <td>0.1871</td>\n",
              "      <td>0.29140</td>\n",
              "      <td>0.16090</td>\n",
              "      <td>0.3029</td>\n",
              "      <td>0.08216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1</td>\n",
              "      <td>16.130</td>\n",
              "      <td>20.68</td>\n",
              "      <td>108.10</td>\n",
              "      <td>798.8</td>\n",
              "      <td>0.11700</td>\n",
              "      <td>0.20220</td>\n",
              "      <td>0.17220</td>\n",
              "      <td>0.10280</td>\n",
              "      <td>0.2164</td>\n",
              "      <td>...</td>\n",
              "      <td>20.96</td>\n",
              "      <td>31.48</td>\n",
              "      <td>136.80</td>\n",
              "      <td>1315.0</td>\n",
              "      <td>0.1789</td>\n",
              "      <td>0.4233</td>\n",
              "      <td>0.47840</td>\n",
              "      <td>0.20730</td>\n",
              "      <td>0.3706</td>\n",
              "      <td>0.11420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1</td>\n",
              "      <td>19.810</td>\n",
              "      <td>22.15</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1260.0</td>\n",
              "      <td>0.09831</td>\n",
              "      <td>0.10270</td>\n",
              "      <td>0.14790</td>\n",
              "      <td>0.09498</td>\n",
              "      <td>0.1582</td>\n",
              "      <td>...</td>\n",
              "      <td>27.32</td>\n",
              "      <td>30.88</td>\n",
              "      <td>186.80</td>\n",
              "      <td>2398.0</td>\n",
              "      <td>0.1512</td>\n",
              "      <td>0.3150</td>\n",
              "      <td>0.53720</td>\n",
              "      <td>0.23880</td>\n",
              "      <td>0.2768</td>\n",
              "      <td>0.07615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0</td>\n",
              "      <td>13.540</td>\n",
              "      <td>14.36</td>\n",
              "      <td>87.46</td>\n",
              "      <td>566.3</td>\n",
              "      <td>0.09779</td>\n",
              "      <td>0.08129</td>\n",
              "      <td>0.06664</td>\n",
              "      <td>0.04781</td>\n",
              "      <td>0.1885</td>\n",
              "      <td>...</td>\n",
              "      <td>15.11</td>\n",
              "      <td>19.26</td>\n",
              "      <td>99.70</td>\n",
              "      <td>711.2</td>\n",
              "      <td>0.1440</td>\n",
              "      <td>0.1773</td>\n",
              "      <td>0.23900</td>\n",
              "      <td>0.12880</td>\n",
              "      <td>0.2977</td>\n",
              "      <td>0.07259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0</td>\n",
              "      <td>13.080</td>\n",
              "      <td>15.71</td>\n",
              "      <td>85.63</td>\n",
              "      <td>520.0</td>\n",
              "      <td>0.10750</td>\n",
              "      <td>0.12700</td>\n",
              "      <td>0.04568</td>\n",
              "      <td>0.03110</td>\n",
              "      <td>0.1967</td>\n",
              "      <td>...</td>\n",
              "      <td>14.50</td>\n",
              "      <td>20.49</td>\n",
              "      <td>96.09</td>\n",
              "      <td>630.5</td>\n",
              "      <td>0.1312</td>\n",
              "      <td>0.2776</td>\n",
              "      <td>0.18900</td>\n",
              "      <td>0.07283</td>\n",
              "      <td>0.3184</td>\n",
              "      <td>0.08183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0</td>\n",
              "      <td>9.504</td>\n",
              "      <td>12.44</td>\n",
              "      <td>60.34</td>\n",
              "      <td>273.9</td>\n",
              "      <td>0.10240</td>\n",
              "      <td>0.06492</td>\n",
              "      <td>0.02956</td>\n",
              "      <td>0.02076</td>\n",
              "      <td>0.1815</td>\n",
              "      <td>...</td>\n",
              "      <td>10.23</td>\n",
              "      <td>15.66</td>\n",
              "      <td>65.13</td>\n",
              "      <td>314.9</td>\n",
              "      <td>0.1324</td>\n",
              "      <td>0.1148</td>\n",
              "      <td>0.08867</td>\n",
              "      <td>0.06227</td>\n",
              "      <td>0.2450</td>\n",
              "      <td>0.07773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>1</td>\n",
              "      <td>15.340</td>\n",
              "      <td>14.26</td>\n",
              "      <td>102.50</td>\n",
              "      <td>704.4</td>\n",
              "      <td>0.10730</td>\n",
              "      <td>0.21350</td>\n",
              "      <td>0.20770</td>\n",
              "      <td>0.09756</td>\n",
              "      <td>0.2521</td>\n",
              "      <td>...</td>\n",
              "      <td>18.07</td>\n",
              "      <td>19.08</td>\n",
              "      <td>125.10</td>\n",
              "      <td>980.9</td>\n",
              "      <td>0.1390</td>\n",
              "      <td>0.5954</td>\n",
              "      <td>0.63050</td>\n",
              "      <td>0.23930</td>\n",
              "      <td>0.4667</td>\n",
              "      <td>0.09946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>1</td>\n",
              "      <td>21.160</td>\n",
              "      <td>23.04</td>\n",
              "      <td>137.20</td>\n",
              "      <td>1404.0</td>\n",
              "      <td>0.09428</td>\n",
              "      <td>0.10220</td>\n",
              "      <td>0.10970</td>\n",
              "      <td>0.08632</td>\n",
              "      <td>0.1769</td>\n",
              "      <td>...</td>\n",
              "      <td>29.17</td>\n",
              "      <td>35.59</td>\n",
              "      <td>188.00</td>\n",
              "      <td>2615.0</td>\n",
              "      <td>0.1401</td>\n",
              "      <td>0.2600</td>\n",
              "      <td>0.31550</td>\n",
              "      <td>0.20090</td>\n",
              "      <td>0.2822</td>\n",
              "      <td>0.07526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>1</td>\n",
              "      <td>16.650</td>\n",
              "      <td>21.38</td>\n",
              "      <td>110.00</td>\n",
              "      <td>904.6</td>\n",
              "      <td>0.11210</td>\n",
              "      <td>0.14570</td>\n",
              "      <td>0.15250</td>\n",
              "      <td>0.09170</td>\n",
              "      <td>0.1995</td>\n",
              "      <td>...</td>\n",
              "      <td>26.46</td>\n",
              "      <td>31.56</td>\n",
              "      <td>177.00</td>\n",
              "      <td>2215.0</td>\n",
              "      <td>0.1805</td>\n",
              "      <td>0.3578</td>\n",
              "      <td>0.46950</td>\n",
              "      <td>0.20950</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.09564</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25 rows × 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bb159c4b-60a3-4a28-9ff2-0f70c4012b17')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bb159c4b-60a3-4a28-9ff2-0f70c4012b17 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bb159c4b-60a3-4a28-9ff2-0f70c4012b17');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df['diagnosis'] = np.where(df['diagnosis']=='M',1, 0)\n",
        "df['diagnosis'].value_counts()\n",
        "df.head(25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKCD08GIqSa6"
      },
      "source": [
        "**Splitting the data into training and testing datasets**\n",
        "\n",
        "\n",
        "In this we are splitting the training data into 80% and testing data into 20%. On Training data, we are also performing k-fold cross validation (where 10 folds are performed in which 9 folds will be used for training and 1 fold is for validating the datasets). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ipeuv3F2pqaa",
        "outputId": "66caa62c-57ea-4e73-b805-5866d2990b13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes of X_train, y_train:  (455, 30) (455,)\n",
            "Shapes of X_test, y_test:  (114, 30) (114,)\n"
          ]
        }
      ],
      "source": [
        "# Spliting the data into training (80%) and testing (20%) sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X = df.drop('diagnosis', axis=1)\n",
        "y = df['diagnosis']\n",
        "X_train, X_test, y_train, y_test = train_test_split (X, y,train_size = 0.8)\n",
        "print ('Shapes of X_train, y_train: ', X_train.shape, y_train.shape)\n",
        "print ('Shapes of X_test, y_test: ', X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YXOavn2q2CT"
      },
      "source": [
        "**Building Random Forest Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EdXsdlbOq0N7"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf_model1 = RandomForestClassifier (random_state = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbilH1q5rhan",
        "outputId": "1da5ea63-bd6a-4de8-9e61-0e19cc5125a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Random Forest model1 accuracy score of 10-fold cross validation:\n",
            " [0.93478261 0.97826087 0.97826087 1.         0.97826087 1.\n",
            " 0.91111111 0.97777778 0.86666667 0.97777778]\n",
            " Random Forest model1 cross validation accuracy mean score: \n",
            " 0.9602898550724637\n"
          ]
        }
      ],
      "source": [
        "# Validate the model's performance using k-fold cross validation\n",
        "from sklearn.model_selection import cross_validate\n",
        "cv = cross_validate (rf_model1, X_train, y_train, cv = 10)\n",
        "print(\" Random Forest model1 accuracy score of 10-fold cross validation:\\n\", cv['test_score'])\n",
        "print(\" Random Forest model1 cross validation accuracy mean score: \\n\", cv['test_score'].mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSfhQUkNsTIK"
      },
      "source": [
        "The k-fold validation allows us to get a generalized estimate performance score of the model. The Random Forest model1 performed pretty well, with an accuracy score of 0.9602 on the training set. However, we still hope to improve the performance by tuning the hyperparameters. \n",
        "\n",
        "Let's see parameters used by the base model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQJiHKhusN1j",
        "outputId": "545118f8-2451-4fb3-ce6e-c6f96a5afe91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest model1 parameters:\n",
            " {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}\n"
          ]
        }
      ],
      "source": [
        "# Checking current parameters of the RandomForest1 model\n",
        "print(\"Random Forest model1 parameters:\\n\", rf_model1.get_params())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKIoyFZVtBkv"
      },
      "source": [
        "**Tuning parameters**\n",
        "\n",
        "We can use RandomizedSearchCV or GridSearchCV with Cross Validation for searching the best parameters. However, RandomizedSearchCV is more suitable when we have not determined any certain parameters, except for boostrapping. \n",
        "\n",
        "Below are parameters that are most important for us to tune:\n",
        "\n",
        "\n",
        "*   'bootstrap': randomly sampling with replacement. We expect to use this method to generate resample of the training data for building trees\n",
        "*   'max_depth': the maximum depth of the tree. It is true that increasing max_depth can improve accuracy of the model on the training set, but the model perform poorly in the unseen data. To avoid the overfitting problem of the Decision Tree that is a fully-grown tree, we should limit this parameter.\n",
        "*   'max_features': for setting the number of features to consider when looking for the best split\n",
        "*   'min_sample_leaf': The minimum number of samples required to be at a leaf node. We will not want one or two sample at each leaf node.\n",
        "*   'min_samples_split':The minimum number of samples required to split an internal node\n",
        "*   'n_estimators': The number of trees in the forest. Note that it is not true that more trees the model has, the better the model performs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-f160SqptAX8",
        "outputId": "e681c48f-26f4-4344-ff7e-341ff6784ceb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'n_estimators': [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000], 'max_features': ['auto', 'sqrt', 'log2'], 'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36], 'min_samples_split': [5, 10, 15], 'min_samples_leaf': [3, 4, 5], 'bootstrap': ['True']}\n"
          ]
        }
      ],
      "source": [
        "# Tuning parameters\n",
        "\n",
        "# Using randomized search on hyperparameters\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Setting a grid of parameters to sample \n",
        "# Setting the number of trees in random forest classifiers\n",
        "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1000, num = 10, endpoint = True)]\n",
        "# Setting the number of features for each tree\n",
        "max_features = ['auto', 'sqrt', 'log2']\n",
        "# Setting the number of depth levels for each tree\n",
        "max_depth = [int(x) for x in np.linspace(start = 3, stop = 36, num=33, endpoint = True)]\n",
        "# Setting the minimum number of samples required to split an internal node\n",
        "min_samples_split = [5, 10, 15]\n",
        "# Setting the minimum number of samples required to be at a leaf node \n",
        "min_samples_leaf = [3, 4, 5]\n",
        "# Select bootstrap method for building trees \n",
        "bootstrap = ['True']\n",
        "\n",
        "# Create the random grid\n",
        "random_grid = {'n_estimators':n_estimators, 'max_features': max_features, 'max_depth': max_depth, 'min_samples_split': min_samples_split,'min_samples_leaf': min_samples_leaf, 'bootstrap': bootstrap}\n",
        "print(random_grid)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a base random forest model for tuning\n",
        "tune_base_rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Create a randomized search cross validation model for searching for the best hyperparameters for the base rf model over 100 parameters combination\n",
        "random_search_rf = RandomizedSearchCV (estimator=tune_base_rf, param_distributions  = random_grid, random_state=42, cv = 10, n_iter=10,n_jobs=-1,verbose=1)\n",
        "\n",
        "# fit the randomized search CV model into the training set\n",
        "random_search_rf.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters\n",
        "random_search_rf.best_params_"
      ],
      "metadata": {
        "id": "Ft5qhCRuKzA9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7a99ca8-2dd5-4142-e82f-b6b8b2f06012"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bootstrap': 'True',\n",
              " 'max_depth': 19,\n",
              " 'max_features': 'sqrt',\n",
              " 'min_samples_leaf': 3,\n",
              " 'min_samples_split': 10,\n",
              " 'n_estimators': 700}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTM9RIyO0KE3"
      },
      "source": [
        "The tuned model did not show to have better performance compared to the base model. That makes sense because we decrease the maximum depths of trees in the tuned model. However, we hope to use those hyperparameters for avoiding the overfitting or high variance of the model on the unseen data. Therefore, we decide to go with the tuned model as our final model."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The tuned random forest model"
      ],
      "metadata": {
        "id": "aJ1BRpM4Zjup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a tuned random forest model with the best parameters choosen by  the cv randomized search algorithm\n",
        "tuned_rf = RandomForestClassifier (n_estimators = 300, min_samples_split = 5, min_samples_leaf = 3, max_features = 'sqrt',  max_depth = 11, bootstrap = True, random_state=42)\n",
        "\n",
        "# Validating the model using k-fold cross validation (k=10)\n",
        "tuned_cv = cross_validate (tuned_rf, X_train, y_train, cv = 10)\n",
        "print(\"The tuned model's accuracy scores in 5-fold cross validation:\\n\", tuned_cv['test_score'])\n",
        "print(\"The final base tuned model's cv accuracy score: \\n\", tuned_cv['test_score'].mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxKA528HYv1h",
        "outputId": "50e7864c-953f-46bb-bd9a-5f1594e43b64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tuned model's accuracy scores in 5-fold cross validation:\n",
            " [0.93478261 0.97826087 0.95652174 0.97826087 0.97826087 1.\n",
            " 0.91111111 0.97777778 0.82222222 0.97777778]\n",
            "The final base tuned model's cv accuracy score: \n",
            " 0.9514975845410628\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above results, it is seen that tuned random forest model has less accuracy this is because we have decreased the maximum depths of the trees. In this we will use hyperparameters for avoiding the overfitting or high variance of the model."
      ],
      "metadata": {
        "id": "n24hPB8kb6lz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3j0-2UPi0VD_"
      },
      "source": [
        "We will be evaluating the model in three metrics. They are:\n",
        "Accuracy, Confusion Matrix and ROC curve."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the selected model to the training set\n",
        "tuned_rf.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98pqmsrjhCX3",
        "outputId": "d8d881e5-51bf-4d14-aa76-23290336470e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(max_depth=11, max_features='sqrt', min_samples_leaf=3,\n",
              "                       min_samples_split=5, n_estimators=300, random_state=42)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Noted that previously we build a model, then train and validate the model with k-fold cross validation. We did not fit the model into the whole training set before applying k-fold cross validation because we tried to prevent data leakage. Otherwise, the model was trained on the whole training set, so when validating with k-fold cross validation, there were no unseen data to validate the model, and that would result a biased estimate score."
      ],
      "metadata": {
        "id": "9xYIzWEGhICT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying the selected model to make prediction on the test set\n",
        "pred = tuned_rf.predict(X_test)\n",
        "\n",
        "# Observing the estimate probability of classess in the test set\n",
        "pred_prob = tuned_rf.predict_proba (X_test)\n",
        "print ('class_0','\\t', 'class_1')\n",
        "print(pred_prob[:10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPB8fPl0hJBb",
        "outputId": "c35e891a-9453-47ad-a572-e87a1dda7593"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class_0 \t class_1\n",
            "[[8.64905483e-01 1.35094517e-01]\n",
            " [1.00000000e+00 0.00000000e+00]\n",
            " [9.90833333e-01 9.16666667e-03]\n",
            " [8.33333333e-04 9.99166667e-01]\n",
            " [9.95936508e-01 4.06349206e-03]\n",
            " [9.29896825e-01 7.01031746e-02]\n",
            " [6.82261905e-02 9.31773810e-01]\n",
            " [9.99166667e-01 8.33333333e-04]\n",
            " [5.28450096e-01 4.71549904e-01]\n",
            " [9.86241703e-01 1.37582973e-02]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The result of the estimate probabilities show how classes were assigned. It is a nx2 array. The first column (dimension) is for class 0, and another for the class 1. In the first instance, it was assigned class 1 because it got a probability of almost 1 for this class."
      ],
      "metadata": {
        "id": "I70zQX64hQNb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # Evaluate the selected model on the test set with acurracy scores\n",
        "print('Accuracy of the selected model in the test set: {:.4f}'.format(tuned_rf.score(X_test, y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLqnJrB5hVTW",
        "outputId": "719a8bcb-d5c2-45f9-e222-d4fdb7033316"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the selected model in the test set: 0.9825\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We got a very high accuracy of the model on the test set."
      ],
      "metadata": {
        "id": "zzW05JiHhaUL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**With confusion matrix**\n",
        "\n",
        "We were aware of the imbalanced proportions of the two classes in previous section. Therefore, accuracy score may not make sense. Note that the Malignant (class 1) acounts a lower portion in the dataset. Even if True Positive is high, and False Negative is low, the cost of False Negative is quite high."
      ],
      "metadata": {
        "id": "2po9qYf_hdPs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the selected model on the test set  with confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "conf_matrix = confusion_matrix(y_test, pred )\n",
        "# visualizing confusion matrix\n",
        "sns.heatmap(conf_matrix, annot = True)\n",
        "plt.xlabel ('predicted values')\n",
        "plt.ylabel ('actual values')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "7cn3Noj2ha1i",
        "outputId": "9ef0dcbe-c68c-437f-8d72-df9398912813"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(33.0, 0.5, 'actual values')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above results on the test dataset by our model, it predicted 70 benign as True Positives and 1 False Negative (Predicted Benign cell as Malignant) and 1 False Positive (Actually Malignant but predicted as Benign) and 42 True Negatives."
      ],
      "metadata": {
        "id": "WOI257DPhvUD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the ROC curve\n",
        "The Receiver Operating Characteristic (ROC) Curve is drew by plotting the true positive rate (TPR) against the false positive rate (FPR). The ROC Curve is a probability curve, telling us how much the model able to distinguish between classes, shown by the area under the curve (AUC). Higher the AUC is, the better the model performs. The AUC is expected to greater than 0.5, or over left-top part compared to the baseline.\n",
        "\n",
        "TPR = TP/P = TP/(TP+FN)\n",
        "FPR = FP/N = FP/ (FP+TN)"
      ],
      "metadata": {
        "id": "jf8UCdpnkcji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "# Taking the probability of the class 1 (Malignant) on the test set\n",
        "pred_prob_c1 = pred_prob[:,1]\n",
        "\n",
        "# Getting True Positive Rate (tpr) and False Positive Rate (fpr)\n",
        "fpr, tpr, threshold = roc_curve (y_test,pred_prob_c1, pos_label = 1)\n",
        "\n",
        "# Computing Area Under the ROC Curve (roc_auc)\n",
        "roc_auc_score = roc_auc_score (y_test,pred_prob_c1)\n",
        "roc_auc_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxgzAvIgkgec",
        "outputId": "a351dcb4-bc69-4152-e7e3-2eb6c5dfc8e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9983622666229938"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the ROC Curve\n",
        "plt.plot( fpr, tpr)\n",
        "plt.plot([0,1], '--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title (\"ROC Curve (AUC = {:.3f})\".format(roc_auc_score))\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "fDXbZhfykkpm",
        "outputId": "0eca5faa-7b32-4fbe-cbbf-b8440cc0dd62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see our AUC is very high, very close to 1 which is the ideal point (1.0). That indicates our model has a very good measure of separability between classes."
      ],
      "metadata": {
        "id": "q-ERjYi7kpLP"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Muktinutalapati_Assignment4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM2amxsNUb2H5WoV+JBS0Ed",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}